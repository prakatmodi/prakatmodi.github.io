[
  {
    "name": "chapter_0.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 0\r\npermalink: /learning/linux/chapter_0.md/\r\nprevious_chapter: /learning/\r\nnext_chapter: /learning/linux/chapter_1.md/\r\n---\r\n\r\n<!-- \r\n@author: Prakat Modi\r\nDate: 2025.03.09\r\nThis is Table of content for the Linux leanring for the beginners\r\n-->\r\n\r\n\r\n<h2 style=\"text-align:center;\" > Guidebook for Linux Server, HPC, PBS System, and CDO </h2>\r\n\r\n---\r\n### Table of Contents\r\n\r\n- [1. Introduction](/learning/linux/chapter_1.md)\r\n  - [1.1. Purpose of the Guide](/learning/linux/chapter_1.md#purpose-of-guide)\r\n  - [1.2. Prerequisites](/learning/linux/chapter_1.md#prerequisites)\r\n- [2. Linux Server Basics](/learning/linux/chapter_2.md)\r\n  - [2.1. Overview of Linux Systems](/learning/linux/chapter_2.md#overview-of-linux-systems)\r\n  - [2.2. Essential Commands](/learning/linux/chapter_2.md#essential-commands)\r\n  - [*References*](/learning/linux/chapter_2.md#references)\r\n- [3. High-Performance Computing (HPC)](/learning/linux/chapter_3.md)\r\n  - [3.1. Overview of High-Performance Computing (HPC): architecture & components](/learning/linux/chapter_3.md#overview-of-high-performance-computing-hpc-architecture-components)\r\n  - [3.2. Connecting to HPC clusters](/learning/linux/chapter_3.md#connecting-to-hpc-clusters)\r\n  - [3.3. Common directories](/learning/linux/chapter_3.md#common-directories)\r\n  - [3.4. Best practices for using HPC](/learning/linux/chapter_3.md#best-practices-for-using-hpc)\r\n  - [*References*](/learning/linux/chapter_3.md#references)\r\n- [4. Portable Batch System (PBS)](/learning/linux/chapter_4.md)\r\n  - [4.1. Overview of PBS & Job Scheduling](/learning/linux/chapter_4.md#overview-of-pbs--job-scheduling)\r\n  - [4.2. Common PBS Commands](/learning/linux/chapter_4.md#common-pbs-commands)\r\n  - [4.3. Creating & Submitting Job Scripts](/learning/linux/chapter_4.md#creating--submitting-job-scripts)\r\n  - [4.4. Job Dependencies & Array Jobs](/learning/linux/chapter_4.md#job-dependencies--array-jobs)\r\n  - [*References*](/learning/linux/chapter_4.md#references)\r\n- [5. Climate Data Operators (CDO)](/learning/linux/chapter_5.md)\r\n  - [5.1. Introduction to CDO](/learning/linux/chapter_5.md#introduction-to-cdo)\r\n  - [5.2. Installation & Setup](/learning/linux/chapter_5.md#installation--setup)\r\n  - [5.3. Some common CDO commands](/learning/linux/chapter_5.md#some-common-cdo-commands)\r\n  - [5.4. Scripting with CDO](/learning/linux/chapter_5.md#scripting-with-cdo)\r\n  - [*References*](/learning/linux/chapter_5.md#references)\r\n- [6. Other useful linux tools](/learning/linux/chapter_6.md)\r\n  - [6.1. rclone](/learning/linux/chapter_6.md#rclone)\r\n  - [6.2. xclip](/learning/linux/chapter_6.md#xclip)\r\n  - [6.2. GNU parallel](/learning/linux/chapter_6.md#gnu-parallel)\r\n- [7. Practical Exercises & Projects](/learning/linux/chapter_7.md)\r\n\r\n  <!-- - [6.1. Linux Basics Practice](/learning/linux/chapter_6.md#linux-basics-practice)\r\n  - [6.2. Submitting and Managing Jobs on HPC with PBS](/learning/linux/chapter_6.md#submitting-and-managing-jobs-on-hpc-with-pbs)\r\n  - [6.3. Working with CDO for Climate Data Analysis](/learning/linux/chapter_6.md#working-with-cdo-for-climate-data-analysis) -->\r\n  \r\n- [8. References & Resources](/learning/linux/chapter_8.md)\r\n  - [8.1. Official Documentation Links](/learning/linux/chapter_8.md#official-documentation-links)\r\n  - [8.2. Recommended Tutorials & Books](/learning/linux/chapter_8.md#recommended-tutorials-books)\r\n\r\n\r\n",
    "path": "linux/chapter_0.md"
  },
  {
    "name": "chapter_1.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 1\r\npermalink: /learning/linux/chapter_1.md/\r\nprevious_chapter: /learning/linux/chapter_0.md/\r\nnext_chapter: /learning/linux/chapter_2.md/\r\n---\r\n\r\n\r\n\r\n<h1 style=\"text-align: center;\">1. Introduction</h1>\r\n\r\n---\r\n\r\n<div style=\"text-align: justify;\">\r\n\r\n\r\n### 1.1. Purpose of guide\r\n\r\nThis is beginner's guide for learning about linux, and related commands and softwares. The guide focuses on the skills required for performing the large scale hydrological, and climate analysis.\r\n\r\n### 1.2. Prerequisite\r\n\r\nThe following software are useful for the inital setup to learn and perform the analysis.\r\n\r\n### SSH (Secure Shell) Clients \r\nThese are softare used to establish authentic and secure connections to the SSH servers. Please install and setup any of these for connecting with lab server. *(click on each to go to downloading page)*.\r\n#### 1. [Mobaxterm](https://mobaxterm.mobatek.net/) \r\n#### 2. [Putty](https://www.putty.org/) \r\n\r\n\r\n### Linux distrous\r\nIf you want use your personal computer for analysis, you can install any of linux distrous like Ubuntu, Debian, etc. You can also install windwons susbsystem for linux (WSL) to use linux within your Windows OS.\r\n\r\n#### [How to install WSL](https://learn.microsoft.com/en-us/windows/wsl/install)\r\n\r\n\r\n</div>\r\n\r\n\r\n\r\n\r\n",
    "path": "linux/chapter_1.md"
  },
  {
    "name": "chapter_2.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 2\r\npermalink: /learning/linux/chapter_2.md/\r\nprevious_chapter: /learning/linux/chapter_1.md/\r\nnext_chapter: /learning/linux/chapter_3.md/\r\n---\r\n\r\n\r\n\r\n<h1 style=\"text-align: center;\">2. Linux server basics</h1>\r\n\r\n---\r\n<div style=\"text-align: justify;\">\r\n\r\n### 2.1. Overview of Linux Systems\r\n\r\nLinux systems are open-source Unix-like operating systems used for many devices like computers, and serveres known for their security and versatility. Key characterstics of the linux systems are:\r\n\r\n- Hierarchical File System\r\n- Command-Line Interface\r\n- Multi-user and Multi-tasking\r\n\r\n### 2.2. Essential Commands\r\n\r\n`ls`: show the list all the files and folders\r\n\r\n`ls -al`: shows the list of files and folders including hidden ones \r\n\r\n`lscpu`: display information about the CPU architecture\r\n\r\n`cd /path`: changing the directory\r\n\r\n`cd ..`: goes to one upward directory\r\n\r\n`mkdir dir_name`: creating new folder\r\n\r\n`rm filename`: delete file\r\n\r\n`rm -r foldername`: delete directoy/folder\r\n\r\n`rm *`: delet all the files in current directory\r\n\r\n`cp`: copy file/s\r\n\r\n`mv`: to moves or rename files (or directories)\r\n\r\n`chmod [option]... {mode | --reference=ref_file} file...`: changes the access permissions of the named files\r\n\r\n`head [option]... [file]...`: prints the first part (10 lines by default) of each file\r\n\r\n`tail [option]... [file]...`: prints the last part (10 lines by default) of each file\r\n\r\n`tar -zcvf file_name.tar.gz directory_name`: tar gzip compression\r\n\r\n`tar -cvf file_name.tar directory_name`: tar compression\r\n\r\n`tar -zxvf file_name.tar.gz`: extraction \r\n\r\n`tar -xvf file_name.tar`: extraction\r\n\r\n\r\n<table style=\"border-collapse: collapse; width: 40% 50% 40%; border: 1px solid gray;\">\r\n  <tr>\r\n    <th style=\"border: 1px solid gray; padding: 4px;\">Option</th>\r\n    <th style=\"border: 1px solid gray; padding: 4px;\">Full Name</th>\r\n    <th style=\"border: 1px solid gray; padding: 4px;\">Meaning</th>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">-z</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">--gzip</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">Specifies gzip format</td>\r\n  </tr>\r\n    <tr>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">-c</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">--create</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">Create a new compressed file</td>\r\n  </tr>\r\n    <tr>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">-v</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">--verbose</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">Output processing results</td>\r\n  </tr>\r\n    <tr>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">-f</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">--file</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">Compressed file name</td>\r\n  </tr>\r\n    <tr>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">-x</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">--extract</td>\r\n    <td style=\"border: 1px solid gray; padding: 4px;\">Extracting files from compressed file</td>\r\n  </tr>\r\n</table>\r\n\r\n\r\n### *References*\r\n- Top (GNU Coreutils 9.6). (n.d.). Retrieved March 20, 2025, from [https://www.gnu.org/software/coreutils/manual/html_node/](https://www.gnu.org/software/coreutils/manual/html_node/)\r\n- Linux tar.gz tar 圧縮 解凍 #Linux - Qiita. (n.d.). Retrieved March 21, 2025, from [https://qiita.com/HyunwookPark/items/047ba2da9ef16bcac356](https://qiita.com/HyunwookPark/items/047ba2da9ef16bcac356)\r\n\r\n\r\n\r\n\r\n\r\n</div>",
    "path": "linux/chapter_2.md"
  },
  {
    "name": "chapter_3.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 3\r\npermalink: /learning/linux/chapter_3.md/\r\nprevious_chapter: /learning/linux/chapter_2.md/\r\nnext_chapter: /learning/linux/chapter_4.md/\r\n---\r\n\r\n\r\n<h1 style=\"text-align: center;\"> 3. High-Performance Computing (HPC) </h1>\r\n\r\n---\r\n<div style=\"text-align: justify;\">\r\n\r\n### 3.1. Overview of High-Performance Computing (HPC): architecture & components\r\n\r\nHigh-Performance Computing (HPC) systems consist of interconnected nodes forming clusters. Its usually a linux based server for managing nodes (i.e. CPUs) to perform large computations. \r\n\r\n<img src=\"{{ site.url }}{{ site.baseurl }}/images/learning/linux/example_server.png\" alt=\"server example\" style=\"width: 900px; float: none; margin-left: 20px; margin-right: 20px; margin-bottom: 10px\" /> <br>\r\n\r\n*[Note: Please click here for details related to H-Lab Server](/images/learning/linux/hlab_server.png)*\r\n\r\n#### Key components include:\r\n\r\n- Login node: The login node is gateway to HPC cluster & calculation nodes. It has small memory and not designed for large calculation and analysis. \r\n- Calculation node: The calculation node have large memory with multi-core processors or GPUs, used to perfom all the analysis. It can be used directly or with PBS command for submitting the job to the calculation node for performing analysis in the background. \r\n- Storage Systems: Hierarchical storage includes high-speed scratch space and permanent home directories.\r\n- Networking: High-speed interconnects (e.g., InfiniBand) enabling fast data transfer between nodes.\r\n- Scheduler/Resource Manager: Software (e.g., [PBS](/learning/linux/chapter_4.md/), SLURM) managing job submissions and resource allocation.\r\n\r\n### 3.2. Connecting to HPC clusters\r\n\r\nAccessing HPC systems typically involves:\r\n\r\n- SSH (Secure Shell): Command-line access using `ssh user@hostname`.\r\n- VPN/Two-Factor Authentication: Sometimes required for secure access.\r\n- File Transfer Tools: `scp`, `rsync`, or GUI-based tools  such as [`winscp`](https://winscp.net/eng/index.php) for moving files between local and remote systems.\r\n\r\n#### `scp`: copies files between hosts on a network \r\n*(see below for command syntex)*\r\n\r\n```\r\nscp [-346ABCOpqRrTv] [-c cipher] [-D sftp_server_path] [-F ssh_config] [-i identity_file] [-J destination] [-l limit] [-o ssh_option] [-P port] [-S program] source ... target\r\n```\r\n*Note: `info scp` will shows all the details realted to scp including options.*\r\n\r\n#### `rsync`: a fast, versatile, remote (and local) file-copying tool \r\n*(see below for command syntex)*\r\n\r\n```\r\nLocal:\r\nrsync [OPTION...] SRC... [DEST]\r\n\r\nAccess via remote shell:\r\nPull:\r\nrsync [OPTION...] [USER@]HOST:SRC... [DEST]\r\nPush:\r\nrsync [OPTION...] SRC... [USER@]HOST:DEST\r\n\r\nAccess via rsync daemon:\r\nPull:\r\nrsync [OPTION...] [USER@]HOST::SRC... [DEST]\r\nrsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]\r\nPush:\r\nrsync [OPTION...] SRC... [USER@]HOST::DEST\r\nrsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST)\r\n```\r\n\r\n*Note: for more details use `info rsync`.*\r\n\r\n### 3.3. Common directories\r\n\r\n- Home Directory: Persistent storage, limited space, suitable for scripts and small files.\r\n- Scratch Directory: High-speed, temporary storage for running computations; not backed up.\r\n- Project Directories: Shared spaces for collaborative research, often with quotas.\r\n- Archival Storage: Long-term, slower storage for completed projects or backups.\r\n\r\n### 3.4. Best practices for using HPC\r\n\r\n- Efficient Resource Usage: Request appropriate resources (CPUs, memory, runtime) for jobs.\r\n- File Management: Regularly clean up scratch space and archive completed projects.\r\n- Job Monitoring: Use tools (qstat, squeue, etc.) to track job status.\r\n- Parallelization: Utilize parallel computing techniques to enhance performance.\r\n- Documentation: Maintain scripts and workflows with comments and version control. (useful for others to use it in future)\r\n\r\n\r\n### *References*\r\n- rsync. (n.d.). Retrieved March 25, 2025, from [https://rsync.samba.org](https://rsync.samba.org)\r\n\r\n\r\n</div>\r\n\r\n\r\n\r\n",
    "path": "linux/chapter_3.md"
  },
  {
    "name": "chapter_4.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 4\r\npermalink: /learning/linux/chapter_4.md/\r\nprevious_chapter: /learning/linux/chapter_3.md/\r\nnext_chapter: /learning/linux/chapter_5.md/\r\n---\r\n\r\n<h1 style=\"text-align:center;\"> 4. Portable Batch System (PBS) </h1>\r\n---\r\n\r\n<div style=\"text-align: justify;\">\r\n\r\n### 4.1. Overview of PBS\r\n\r\nPortable Batch System (PBS) is a computer software that performs job scheduling often used in UNIX cluster environment. Its primary task is to allocate computational tasks, i.e., batch jobs, among the available computing resources. Torque PBS is used as a PBS system for optimizig job scheduling and workload management in high-performance computing (HPC) system for H-Lab server.\r\n\r\n### 4.2. Common PBS Commands\r\n#### qsub\r\n`qsub`: Submits a job for processing. \r\n\r\nOptions:\r\n\r\n`-q <queue>`: Specifies the queue to submit the job to. \r\n\r\n`-V`: Passes all environment variables to the job. \r\n\r\n`-v var[=value]`: Passes a specific environment variable to the job. \r\n\r\n`-b y`: Allows command to be a binary file instead of a script. \r\n\r\n`-w e`: Verifies options and aborts if there is an error. \r\n\r\n`-N <jobname>`: Sets the name of the job. \r\n\r\n`-l resource_list`: Specifies resources. \r\n\r\n`-m`: mail options.\r\n\r\n`-M`: user list whom mail is sent.\r\n\r\n`qsub -I -X`: Run the interactive session with default node.\r\n\r\n`qsub -q -I queue_name -l select=number_of_nodes:ncpus=no_of_cpus_each_node:mem=total_memory`: Running interactive session with defined resources.\r\n\r\n#### qstat\r\n`qstat`: Monitors the status of jobs and queues.\r\n\r\n`qstat -Q queue_name`: Shows the details of requested queue.\r\n\r\n`qstat -q queue_name`: Shows the list of all the queues and their details.\r\n\r\n`qstat -fQ queue_name`: Shows the details of each queue seperately.\r\n\r\n#### qdel\r\n`qdel job_name`: Terminates a job before its completion. \r\n\r\n#### qalter\r\n`qalter`: Modifies queued batch jobs. \r\n\r\n#### pbsnodes\r\n`pbsnodes -a`: Details of the nodes.\r\n\r\n`pbsnodes -aS`: Details of the nodes as table.\r\n\r\n`pbsnodes -aSj`: Details of the nodes as table.\r\n\r\n#### qhold\r\n`qhold [{-h <HOLD LIST>|-t <array_range>}] <JOBID>[ <JOBID>] ...`: server place one or more holds on a job (i.e., not eligible for execution).\r\n\r\n### 4.3. PBS scripts \r\nKeep the follwoing in the begining og the code after first line i.e.`!/bin/sh`\r\n``` \r\n#*** PBS setting (modify as per need)\r\n#PBS -q Queue_Name \r\n#PBS -l select=number_of_nodes:ncpus=no_of_cpus_each_node:mem=total_memory\r\n#PBS -j oe\r\n#PBS -m ea\r\n#PBS -V\r\n#PBS -M mail_address \r\n```\r\n\r\n### *References*\r\n\r\n- Portable Batch System - Wikipedia. (n.d.). Retrieved March 25, 2025, from [https://en.wikipedia.org/wiki/Portable_Batch_System](https://en.wikipedia.org/wiki/Portable_Batch_System)\r\n- Commands overview. (n.d.). Retrieved March 25, 2025, from [https://docs.adaptivecomputing.com/torque/4-1-4/help.htm#topics/12-appendices/commandsOverview.htm](https://docs.adaptivecomputing.com/torque/4-1-4/help.htm#topics/12-appendices/commandsOverview.htm)\r\n\r\n\r\n</div>\r\n\r\n",
    "path": "linux/chapter_4.md"
  },
  {
    "name": "chapter_5.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 5\r\npermalink: /learning/linux/chapter_5.md/\r\nprevious_chapter: /learning/linux/chapter_4.md/\r\nnext_chapter: /learning/linux/chapter_6.md/\r\n---\r\n\r\n\r\n<h1 style=\"text-align:center;\"> 5. Climate Data Operators (CDO) </h1>\r\n\r\n---\r\n\r\n<div style=\"text-align: justify;\">\r\n\r\n### 5.1. Introduction to CDO\r\n\r\nClimate data operators (CDO) is a collection of command line Operators to manipulate and analyse climate and numerical weather prediction data. CDO user guide can be downloaded from [https://code.mpimet.mpg.de/projects/cdo/embedded/cdo.pdf](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo.pdf). It contains more than 600 operators and supports GRIB 1/2 , netCDF 3/4, SERVICE, EXTRA and IEG.\r\n\r\n### 5.2. Installation & Setup\r\nCDO can be downloaded with the following commands on linux system:\r\n\r\n`apt-get install cdo` or\r\n\r\n`sudo apt-get install cdo` \r\n\r\n*Note: check the of CDO operator availaiblity before installation*\r\n\r\n### 5.3. Some common CDO commands\r\n`cdo info file_name`: Prints information and simple statistics for each field of all input datasets.\r\n\r\n`cdo sinfo filename`: Prints short information of a dataset.\r\n\r\n\r\n`cdo seltimestep,timestep file_in file_out`: Selects a specific timestep.\r\n\r\n`cdo seldate,date file_in file_out`: Selects data by date.\r\n\r\n`cdo selmon,month file_in file_out`: Selects data by month.\r\n\r\n`cdo selday,day file_in file_out`: Selects data by day.\r\n\r\n`cdo selhour,hour file_in file_out`: Selects data by hour.\r\n\r\n`cdo selgrid,grid_name file_in file_out`: Selects data by grid.\r\n\r\n`cdo selindexbox,x1,x2,y1,y2 file_in file_out`: Selects a rectangular area.\r\n\r\n`cdo timmean file_in file_out`: Calculates the temporal mean.\r\n\r\n`cdo timsum file_in file_out`: Calculates the temporal sum.\r\n\r\n`cdo timmin file_in file_out`: Calculates the temporal minimum.\r\n\r\n`cdo timmax file_in file_out`: Calculates the temporal maximum.\r\n\r\n`cdo daymean file_in file_out`: Calculates the daily mean.\r\n\r\n`cdo monmean file_in file_out`: Calculates the monthly mean.\r\n\r\n`cdo yearmean file_in file_out`: Calculates the yearly mean.\r\n\r\n`cdo ensmean file_in file_out`: Calculates the ensemble mean.\r\n\r\n`cdo gridarea file_in file_out`: Calculates the grid cell area.\r\n\r\n`cdo areaavg file_in file_out`: Calculates the area-weighted average.\r\n\r\n`cdo areasum file_in file_out`: Calculates the area-weighted sum.\r\n\r\n`cdo mulc,number file_in file_out`: Multiplies by a constant.\r\n\r\n`cdo addc,number file_in file_out`: Adds a constant.\r\n\r\n`cdo mul file_in1 file_in2 file_out`: Multiplies two datasets.\r\n\r\n`cdo add file_in1 file_in2 file_out`: Adds two datasets.\r\n\r\n`cdo sub file_in1 file_in2 file_out`: Subtracts two datasets.\r\n\r\n`cdo div file_in1 file_in2 file_out`: Divides two datasets.\r\n\r\n`cdo remapbil,grid_file file_in file_out`: Bilinear remapping.\r\n\r\n`cdo remapnn,grid_file file_in file_out`: Nearest neighbor remapping.\r\n\r\n`cdo remapcon,grid_file file_in file_out`: Conservative remapping.\r\n\r\n`cdo vertmean,levels file_in file_out`: Calculates the vertical mean.\r\n\r\n`cdo vertsum,levels file_in file_out`: Calculates the vertical sum.\r\n\r\n`cdo merge file_in1 file_in2 file_out`: Merges two datasets.\r\n\r\n`cdo mergetime file_in1 file_in2 file_out`: Merges two datasets over time.\r\n\r\n### 5.4. Scripting with CDO\r\n\r\nCDO operators can be combined together using a shell script to automate and perform complex tasks for processing large datasets. e.g., The follwoing code used to do multiple analysis to process it in required format for the further analysis. \r\n\r\n```\r\n# The code process the runoff data by combining mutiple operators as follows:\r\n# -vertsum: sum all the vertical levels into one\r\n# -chunit: change the unit from  \"kg/m**2/s\" to \"mm day-1\"\r\n# -remapbil: perform bilinear interpolation based on the properties of \"resample/grid_30min.txt\" file\r\n# -mulc: multiplication with 86400\r\n# -shifttime: shift each year by 80 year (e.g., if years are 1990,1991, it becomes 2070,2071)\r\n# chname: chnage the name of the varibale\r\n# splityear: create the separte file for each year with name CM_${var}_global30_day_Runoff_YYYY\r\n# -f nc4 -z zip: creates zip compressed netcdf 4 file output\r\n\r\n\r\nBASE='/dir_1/dir_1_1/raw_data'      # directory for the all raw data\r\necho ${BASE}                        # print the path\r\ncd ${BASE}                          # change the current direcoty to BASE directory\r\n\r\nNC_FILE=$(ls *.nc)                  # make a list of all the availbale netcdf files\r\n\r\nfor FILE in ${NC_FILE}              # loop over all the files\r\ndo\r\n    echo ${FILE}                        # print file_name\r\n\r\n    var=$(echo ${FILE} | cut -c 1-5)    # take out 1st to 5th characters\r\n\r\n    cdo -f nc chname,RUNOFF,Runoff -shifttime,80year -mulc,86400 -remapbil,\"/dir_1/resample/grid_30min.txt\" \r\n    -chunit,\"kg/m**2/s\",\"mm day-1\" -vertsum $FILE temp1.nc\r\n\r\n    cdo -f nc4 -z zip splityear temp1.nc CM_${var}_global30_day_Runoff_         # final processed data\r\n\r\n    rm temp1.nc\r\n\r\n    mv CM_*.nc /dir_1/dir_1_1/pr_data/ssp370tph/          # moving final processed data\r\ndone\r\n\r\n# content for dir_1/resample/grid_30min.txt file (used for 30-arcmin resampling NtoS):\r\ngridtype=lonlat\r\nxsize=720\r\nysize=360\r\nxfirst=-179.75\r\nxinc=0.50\r\nyfirst=89.75\r\nyinc=-0.50\r\n```\r\n\r\n### *References*\r\n- Overview - CDO - Project Management Service. (n.d.). Retrieved March 25, 2025, from [https://code.mpimet.mpg.de/projects/cdo](https://code.mpimet.mpg.de/projects/cdo)\r\n\r\n\r\n</div>",
    "path": "linux/chapter_5.md"
  },
  {
    "name": "chapter_6.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 6\r\npermalink: /learning/linux/chapter_6.md/\r\nprevious_chapter: /learning/linux/chapter_5.md/\r\nnext_chapter: /learning/linux/chapter_7.md/\r\n---\r\n\r\n<h1 style=\"text-align:center;\"> 6. Other useful linux tools </h1>\r\n---\r\n\r\n<div style=\"text-align: justify;\">\r\n\r\n### 6.1. [Rclone](https://rclone.org/)\r\nRclone is a command-line program to manage files on cloud storage. It helps to sync your data from your cloud storage to the local storage. It can be installed follwoing way without root permission in your system.\r\n\r\n\r\n#### 6.1.1. Download and extract\r\nYou can download linux [Intel/AMD - 64 Bit](https://rclone.org/downloads/) or clone it from [github repository](https://github.com/rclone/rclone/releases/tag/v1.69.1) using follwoing command.\r\n```\r\n# download\r\nwget https://downloads.rclone.org/v1.69.1/rclone-v1.69.1-linux-amd64.zip\r\n\r\n# extract\r\nunzip rclone... \r\n\r\n```\r\n\r\n#### 6.1.2. Set up rclone to use as follows\r\n\r\n```\r\n# change the directory\r\ncd rclone... (unzipped directory)\r\n\r\n# for setting rclone (create ~/.local/bin and ~/.local/share/man/ folders if not preexist)\r\ncp rclone ~/.local/bin\r\nchmod +x ~/.local/bin/rclone\r\ncp rclone.1 ~/.local/share/man/man1/\r\n```\r\n\r\nFor setting google drive using rclone check here https://rclone.org/drive/\r\n\r\n### 6.2. [xclip](https://github.com/astrand/xclip)\r\nIts a command line ultility for using clipboard. Its very helpful copying the selection without using mouse. You can set the xclip without root permission as follows.\r\n\r\n#### 6.2.1 Download and extract\r\nClone the repository using follwoing code.\r\n\r\n`git clone https://github.com/astrand/xclip.git`\r\n\r\nIt can be downloaded and extracted as follows also:\r\n\r\n```\r\n# download\r\nwget https://versaweb.dl.sourceforge.net/project/xclip/xclip/0.12/xclip-0.12.tar.gz\r\n\r\n# extract files\r\ntar xvzf xclip-${XCLIP_VERSION}.tar.gz\r\n```\r\n\r\n#### 6.2.2 Set up xclip for the system\r\n\r\n```\r\n# change the directory \r\ncd xclip...\r\n\r\n# configure and install (make local folder if not preexist)\r\n./configure --prefix=$HOME/local --disable-shared\r\nmake\r\nmake install\r\n\r\n# add PATH in bashrc\r\nexport PATH=\"$HOME/local/bin:$PATH\"\r\n```\r\n\r\n### 6.3. [GNU parallel](https://www.gnu.org/software/parallel/)\r\nIts a shell tool for executing jobs in parallel using multiple computers/processors. A job can be a single command or a small script that has to be run for each of the lines in the input. The documentation for use can be downloaded from https://zenodo.org/records/1146014 \r\n\r\n#### 6.3.1 Download and extract\r\n```\r\n# download\r\nwget https://ftp.gnu.org/gnu/parallel/parallel-20120122.tar.bz2\r\n\r\n# extract\r\ntar -xf parllel...\r\n```\r\n\r\n#### 6.3.1. set up GNU parallel\r\n```\r\n# change directory\r\ncd parallel...\r\n\r\n# configure\r\n./configure --prefix=$HOME/local --disable-shared\r\nmake\r\nmake install\r\n\r\n# add PATH in bashrc if not available\r\nexport PATH=\"$HOME/local/bin:$PATH\"\r\n```\r\n",
    "path": "linux/chapter_6.md"
  },
  {
    "name": "chapter_7.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 7\r\npermalink: /learning/linux/chapter_7.md/\r\nprevious_chapter: /learning/linux/chapter_6.md/\r\nnext_chapter: /learning/linux/chapter_8.md/\r\n---\r\n\r\n<h1 style=\"text-align:center;\"> 7. Practical Exercises & Projects </h1>\r\n---\r\n\r\n### Under Construction  ...\r\n\r\n\r\n<!-- ## 6.1. Linux Basics Practice\r\n## 6.2. Submitting and Managing Jobs on HPC with PBS\r\n## 6.3. Working with CDO for Climate Data Analysis\r\n## 6.4. Combining Tools for End-to-End Workflow -->",
    "path": "linux/chapter_7.md"
  },
  {
    "name": "chapter_8.md",
    "content": "---\r\nlayout: learning_data\r\ntitle: Chapter 8\r\npermalink: /learning/linux/chapter_8.md/\r\nprevious_chapter: /learning/linux/chapter_7.md/\r\nnext_chapter: /learning/\r\n---\r\n\r\n\r\n\r\n<h1 style=\"text-align:center;\"> 8. References & Resources </h1>\r\n\r\n---\r\n\r\n### 7.1. Official Documentation Links\r\n- Top (GNU Coreutils 9.6). (n.d.). Retrieved March 20, 2025, from [https://www.gnu.org/software/coreutils/manual/html_node/](https://www.gnu.org/software/coreutils/manual/html_node/)\r\n- rsync. (n.d.). Retrieved March 25, 2025, from [https://rsync.samba.org](https://rsync.samba.org)\r\n- Commands overview. (n.d.). Retrieved March 25, 2025, from [https://docs.adaptivecomputing.com/torque/4-1-4/help.htm#topics/12-appendices/commandsOverview.htm](https://docs.adaptivecomputing.com/torque/4-1-4/help.htm#topics/12-appendices/commandsOverview.htm)\r\n\r\n### 7.2. Recommended Tutorials & Books\r\nUnder Construction ...\r\n\r\n\r\n\r\n",
    "path": "linux/chapter_8.md"
  }
]